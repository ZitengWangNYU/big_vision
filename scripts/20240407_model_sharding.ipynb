{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/vlm-pd/miniconda3/envs/vlm/lib/python3.11/site-packages/IPython/core/magics/osm.py:393: UserWarning: using bookmarks requires you to install the `pickleshare` library.\n",
      "  bkms = self.shell.db.get('bookmarks', {})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/austinwang/my_repo/big_vision\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-11 04:55:13.840442: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "%cd ~/my_repo/big_vision\n",
    "import jax\n",
    "import importlib\n",
    "import numpy as np\n",
    "from absl import logging\n",
    "import jax.numpy as jnp\n",
    "from jax.experimental import mesh_utils\n",
    "\n",
    "import big_vision.utils as u\n",
    "import big_vision.optax as bv_optax\n",
    "import big_vision.sharding as bv_sharding\n",
    "import big_vision.input_pipeline as input_pipeline\n",
    "from big_vision.configs.proj.image_text.siglip_replication import get_config\n",
    "\n",
    "config = get_config()\n",
    "model_mod = importlib.import_module(f\"big_vision.models.{config.model_name}\")\n",
    "for m in config.get(\"pp_modules\", [\"ops_general\", \"ops_image\", \"ops_text\"]): importlib.import_module(f\"big_vision.pp.{m}\")\n",
    "def bytes_in_use_devices(): return [device.memory_stats()['bytes_in_use'] for device in jax.devices()]\n",
    "def info(s, *a): logging.info(\"\\u001b[33mNOTE\\u001b[0m: \" + s, *a)\n",
    "def write_note(note): \n",
    "\tif jax.process_index() == 0: info(\"%s\", note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/vlm-pd/miniconda3/envs/vlm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "WARNING:absl:You use TensorFlow DType <dtype: 'int64'> in tfds.features This will soon be deprecated in favor of NumPy DTypes. In the meantime it was converted to int64.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /mnt/vlm-pd/miniconda3/envs/vlm/lib/python3.11/site-packages/tensorflow_datasets/core/reader.py:101: CounterV2 (from tensorflow.python.data.experimental.ops.counter) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.counter(...)` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /mnt/vlm-pd/miniconda3/envs/vlm/lib/python3.11/site-packages/tensorflow_datasets/core/reader.py:101: CounterV2 (from tensorflow.python.data.experimental.ops.counter) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.counter(...)` instead.\n"
     ]
    }
   ],
   "source": [
    "config.model.image['scan'] = True\n",
    "config.model.text['scan'] = True\n",
    "config.model.image['dtype_mm'] = \"float32\"\n",
    "model = model_mod.Model(**config.get(\"model\", {}))\n",
    "train_ds, ntrain_img = input_pipeline.training(config.input)\n",
    "batch_size = config.input.batch_size\n",
    "total_steps = u.steps(\"total\", config, ntrain_img, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1046287/488954300.py:2: DeprecationWarning: jax.tree_map is deprecated: use jax.tree.map (jax v0.4.25 or newer) or jax.tree_util.tree_map (any JAX version).\n",
      "  batch = jax.tree_map(lambda x: jnp.zeros(x.shape, x.dtype.as_numpy_dtype),train_ds.element_spec)\n"
     ]
    }
   ],
   "source": [
    "def init(rng):\n",
    "\tbatch = jax.tree_map(lambda x: jnp.zeros(x.shape, x.dtype.as_numpy_dtype),train_ds.element_spec)\n",
    "\tparams = model.init(rng, batch[\"image\"], batch[\"labels\"])[\"params\"]\n",
    "\t# Set bias in the head to a low value, such that loss is small initially.\n",
    "\tif \"init_head_bias\" in config: params[\"head\"][\"bias\"] = jnp.full_like(params[\"head\"][\"bias\"],config[\"init_head_bias\"])\n",
    "\treturn params\n",
    "\n",
    "write_note(\"Inferring parameter shapes...\")\n",
    "rng = jax.random.PRNGKey(u.put_cpu(config.get(\"seed\", 0)))\n",
    "rng, rng_init = jax.random.split(rng)\n",
    "params_shape = jax.eval_shape(init, rng_init)\n",
    "\n",
    "write_note(\"Inferring optimizer state shapes...\")\n",
    "tx, sched_fns = bv_optax.make(config, params_shape, sched_kw=dict(total_steps=total_steps, batch_size=batch_size, data_size=ntrain_img))\n",
    "opt_shape = jax.eval_shape(tx.init, params_shape)\n",
    "sched_fns_cpu = [u.jit_cpu()(sched_fn) for sched_fn in sched_fns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mesh: Mesh('data': 4)\n",
      "sharding_strategy: [('.*', 'fsdp(axis=\"data\", min_size_to_shard_mb=1)')]\n",
      "train_state_sharding: {'opt': (MaskedState(inner_state=EmptyState()), MaskedState(inner_state=ScaleByAdamState(count=NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec()), mu={'b': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None,)), 'img': {'MAPHead_0': {'LayerNorm_0': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None,)), 'scale': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None,))}, 'MlpBlock_0': {'Dense_0': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None,)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, 'data'))}, 'Dense_1': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None,)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec('data', None))}}, 'MultiHeadDotProductAttention_0': {'key': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec('data', None, None))}, 'out': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None,)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None, 'data'))}, 'query': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec('data', None, None))}, 'value': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec('data', None, None))}}, 'probe': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None, None))}, 'Transformer': {'encoder_norm': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None,)), 'scale': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None,))}, 'encoderblock': {'LayerNorm_0': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None)), 'scale': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None))}, 'LayerNorm_1': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None)), 'scale': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None))}, 'MlpBlock_0': {'Dense_0': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None, 'data'))}, 'Dense_1': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, 'data', None))}}, 'MultiHeadDotProductAttention_0': {'key': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None, None)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, 'data', None, None))}, 'out': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None, None, 'data'))}, 'query': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None, None)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, 'data', None, None))}, 'value': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None, None)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, 'data', None, None))}}}}, 'embedding': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None,)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None, None, 'data'))}, 'pos_embedding': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None, None))}, 't': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None,)), 'txt': {'Embed_0': {'embedding': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec('data', None))}, 'Encoder_0': {'encoder_norm': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None,)), 'scale': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None,))}, 'encoderblock': {'LayerNorm_0': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None)), 'scale': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None))}, 'LayerNorm_1': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None)), 'scale': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None))}, 'MlpBlock_0': {'Dense_0': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None, 'data'))}, 'Dense_1': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, 'data', None))}}, 'MultiHeadDotProductAttention_0': {'key': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None, None)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, 'data', None, None))}, 'out': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None, None, 'data'))}, 'query': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None, None)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, 'data', None, None))}, 'value': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None, None)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, 'data', None, None))}}}}, 'head': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None,)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, 'data'))}, 'pos_embedding': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None, None))}}, nu={'b': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None,)), 'img': {'MAPHead_0': {'LayerNorm_0': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None,)), 'scale': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None,))}, 'MlpBlock_0': {'Dense_0': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None,)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, 'data'))}, 'Dense_1': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None,)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec('data', None))}}, 'MultiHeadDotProductAttention_0': {'key': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec('data', None, None))}, 'out': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None,)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None, 'data'))}, 'query': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec('data', None, None))}, 'value': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec('data', None, None))}}, 'probe': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None, None))}, 'Transformer': {'encoder_norm': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None,)), 'scale': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None,))}, 'encoderblock': {'LayerNorm_0': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None)), 'scale': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None))}, 'LayerNorm_1': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None)), 'scale': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None))}, 'MlpBlock_0': {'Dense_0': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None, 'data'))}, 'Dense_1': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, 'data', None))}}, 'MultiHeadDotProductAttention_0': {'key': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None, None)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, 'data', None, None))}, 'out': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None, None, 'data'))}, 'query': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None, None)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, 'data', None, None))}, 'value': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None, None)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, 'data', None, None))}}}}, 'embedding': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None,)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None, None, 'data'))}, 'pos_embedding': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None, None))}, 't': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None,)), 'txt': {'Embed_0': {'embedding': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec('data', None))}, 'Encoder_0': {'encoder_norm': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None,)), 'scale': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None,))}, 'encoderblock': {'LayerNorm_0': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None)), 'scale': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None))}, 'LayerNorm_1': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None)), 'scale': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None))}, 'MlpBlock_0': {'Dense_0': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None, 'data'))}, 'Dense_1': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, 'data', None))}}, 'MultiHeadDotProductAttention_0': {'key': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None, None)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, 'data', None, None))}, 'out': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None, None, 'data'))}, 'query': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None, None)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, 'data', None, None))}, 'value': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None, None)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, 'data', None, None))}}}}, 'head': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None,)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, 'data'))}, 'pos_embedding': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None, None))}})), EmptyState(), MaskedState(inner_state=EmptyState()), MaskedState(inner_state=ScaleByScheduleState(count=NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec()))), MaskedState(inner_state=EmptyState()), EmptyState()), 'params': {'b': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None,)), 'img': {'MAPHead_0': {'LayerNorm_0': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None,)), 'scale': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None,))}, 'MlpBlock_0': {'Dense_0': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None,)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, 'data'))}, 'Dense_1': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None,)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec('data', None))}}, 'MultiHeadDotProductAttention_0': {'key': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec('data', None, None))}, 'out': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None,)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None, 'data'))}, 'query': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec('data', None, None))}, 'value': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec('data', None, None))}}, 'probe': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None, None))}, 'Transformer': {'encoder_norm': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None,)), 'scale': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None,))}, 'encoderblock': {'LayerNorm_0': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None)), 'scale': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None))}, 'LayerNorm_1': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None)), 'scale': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None))}, 'MlpBlock_0': {'Dense_0': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None, 'data'))}, 'Dense_1': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, 'data', None))}}, 'MultiHeadDotProductAttention_0': {'key': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None, None)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, 'data', None, None))}, 'out': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None, None, 'data'))}, 'query': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None, None)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, 'data', None, None))}, 'value': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None, None)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, 'data', None, None))}}}}, 'embedding': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None,)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None, None, 'data'))}, 'pos_embedding': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None, None))}, 't': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None,)), 'txt': {'Embed_0': {'embedding': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec('data', None))}, 'Encoder_0': {'encoder_norm': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None,)), 'scale': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None,))}, 'encoderblock': {'LayerNorm_0': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None)), 'scale': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None))}, 'LayerNorm_1': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None)), 'scale': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None))}, 'MlpBlock_0': {'Dense_0': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None, 'data'))}, 'Dense_1': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, 'data', None))}}, 'MultiHeadDotProductAttention_0': {'key': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None, None)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, 'data', None, None))}, 'out': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None, None, 'data'))}, 'query': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None, None)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, 'data', None, None))}, 'value': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None, None)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, 'data', None, None))}}}}, 'head': {'bias': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None,)), 'kernel': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, 'data'))}, 'pos_embedding': NamedSharding(mesh=Mesh('data': 4), spec=PartitionSpec(None, None, None))}}}\n"
     ]
    }
   ],
   "source": [
    "config.mesh = [(\"data\",-1)]\n",
    "# config.mesh = [(\"data\", 2),('fsdp', 2)]\n",
    "# config.sharding_strategy = [('.*', 'replicate')]\n",
    "config.sharding_strategy = [('.*', 'fsdp(axis=\"data\", min_size_to_shard_mb=1)')]\n",
    "\n",
    "write_note(\"Setting up mesh...\")\n",
    "config_mesh = config.get(\"mesh\", [(\"data\", jax.device_count())])\n",
    "sharding_rules = config.get(\"sharding_rules\", [(\"act_batch\", \"data\")])\n",
    "mesh_axes, mesh_size = tuple(zip(*config_mesh))\n",
    "mesh_size = np.array(jax.devices()).reshape(mesh_size).shape\n",
    "device_mesh = mesh_utils.create_device_mesh(mesh_size)\n",
    "devices_flat = device_mesh.flatten()\n",
    "\n",
    "write_note(\"Creating device mesh...\")\n",
    "mesh = jax.sharding.Mesh(device_mesh, mesh_axes)\n",
    "print(f\"mesh: {mesh}\")\n",
    "repl_sharding = jax.sharding.NamedSharding(mesh, jax.sharding.PartitionSpec())\n",
    "# print(f\"repl_sharding: {repl_sharding}\")\n",
    "\n",
    "write_note(\"Inferring shardings...\")\n",
    "train_state_shape = {\"params\": params_shape, \"opt\": opt_shape}\n",
    "strategy = config.get(\"sharding_strategy\", [(\".*\", \"replicate\")])\n",
    "print(f\"sharding_strategy: {strategy}\")\n",
    "train_state_sharding = bv_sharding.infer_sharding(train_state_shape, strategy=strategy, mesh=mesh)\n",
    "print(f\"train_state_sharding: {train_state_sharding}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">   CPU 0    </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;255;255;255;48;2;57;59;121m   \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121mCPU 0\u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m    \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jax.debug.visualize_array_sharding(rng_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bytes_in_use_devices() before rng_init reshard: [12800, 12800, 12800, 12800]\n",
      "bytes_in_use_devices() after rng_init reshard: [13312, 13312, 13312, 13312]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">TPU 0,1,2,3 </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;255;255;255;48;2;57;59;121mTPU 0,1,2,3\u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m \u001b[0m\n",
       "\u001b[38;2;255;255;255;48;2;57;59;121m            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "write_note(\"Transferring train_state to devices...\")\n",
    "\n",
    "print(f\"bytes_in_use_devices() before rng_init reshard: {bytes_in_use_devices()}\")\n",
    "# RNG is always replicated\n",
    "rng_init = u.reshard(rng_init, repl_sharding)\n",
    "print(f\"bytes_in_use_devices() after rng_init reshard: {bytes_in_use_devices()}\")\n",
    "jax.debug.visualize_array_sharding(rng_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bytes_in_use_devices() after init reshard: [236578816, 236578816, 236578816, 236578816]\n",
      "bytes_in_use_devices() after tx.init reshard: [688075264, 688075264, 688075264, 688075264]\n",
      "bytes_in_use_devices() after rng_loop reshard: [688075776, 688075776, 688075776, 688075776]\n"
     ]
    }
   ],
   "source": [
    "params = jax.jit(init, out_shardings=train_state_sharding[\"params\"])(rng_init)\n",
    "print(f\"bytes_in_use_devices() after init reshard: {bytes_in_use_devices()}\")\n",
    "\n",
    "opt = jax.jit(tx.init, out_shardings=train_state_sharding[\"opt\"])(params)\n",
    "print(f\"bytes_in_use_devices() after tx.init reshard: {bytes_in_use_devices()}\")\n",
    "\n",
    "rng, rng_loop = jax.random.split(rng, 2)\n",
    "rng_loop = u.reshard(rng_loop, repl_sharding)\n",
    "print(f\"bytes_in_use_devices() after rng_loop reshard: {bytes_in_use_devices()}\")\n",
    "del rng  # not used anymore, so delete it.\n",
    "\n",
    "train_state = {\"params\": params, \"opt\": opt}\n",
    "del params, opt  # Delete to avoid memory leak or accidental reuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img keys: dict_keys(['encoder_norm', 'encoderblock_0', 'encoderblock_1', 'encoderblock_10', 'encoderblock_11', 'encoderblock_2', 'encoderblock_3', 'encoderblock_4', 'encoderblock_5', 'encoderblock_6', 'encoderblock_7', 'encoderblock_8', 'encoderblock_9'])\n",
      "txt keys: dict_keys(['encoder_norm', 'encoderblock_0', 'encoderblock_1', 'encoderblock_10', 'encoderblock_11', 'encoderblock_2', 'encoderblock_3', 'encoderblock_4', 'encoderblock_5', 'encoderblock_6', 'encoderblock_7', 'encoderblock_8', 'encoderblock_9'])\n",
      "total_img_elements: 249838\n",
      "total_txt_elements: 265009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_658423/755717367.py:4: DeprecationWarning: jax.tree_map is deprecated: use jax.tree.map (jax v0.4.25 or newer) or jax.tree_util.tree_map (any JAX version).\n",
      "  img_shapes = jax.tree_map(lambda x: x.shape, train_state['params']['img'])\n",
      "/tmp/ipykernel_658423/755717367.py:5: DeprecationWarning: jax.tree_map is deprecated: use jax.tree.map (jax v0.4.25 or newer) or jax.tree_util.tree_map (any JAX version).\n",
      "  txt_shapes = jax.tree_map(lambda x: x.shape, train_state['params']['txt'])\n",
      "/tmp/ipykernel_658423/755717367.py:9: DeprecationWarning: jax.tree_leaves is deprecated: use jax.tree.leaves (jax v0.4.25 or newer) or jax.tree_util.tree_leaves (any JAX version).\n",
      "  total_img_elements = sum(np.prod(shape) for shape in jax.tree_leaves(img_shapes))\n",
      "/tmp/ipykernel_658423/755717367.py:10: DeprecationWarning: jax.tree_leaves is deprecated: use jax.tree.leaves (jax v0.4.25 or newer) or jax.tree_util.tree_leaves (any JAX version).\n",
      "  total_txt_elements = sum(np.prod(shape) for shape in jax.tree_leaves(txt_shapes))\n"
     ]
    }
   ],
   "source": [
    "# get tree of keys in train_state['params'] with values becoming shapes\n",
    "print(f\"img keys: {train_state['params']['img']['Transformer'].keys()}\")\n",
    "print(f\"txt keys: {train_state['params']['txt']['Encoder_0'].keys()}\")\n",
    "img_shapes = jax.tree_map(lambda x: x.shape, train_state['params']['img'])\n",
    "txt_shapes = jax.tree_map(lambda x: x.shape, train_state['params']['txt'])\n",
    "# print(f\"img_shapes: {img_shapes}\")\n",
    "# print(f\"txt_shapes: {txt_shapes}\")\n",
    "# calculate total number of elements in train_state['params']\n",
    "total_img_elements = sum(np.prod(shape) for shape in jax.tree_leaves(img_shapes))\n",
    "total_txt_elements = sum(np.prod(shape) for shape in jax.tree_leaves(txt_shapes))\n",
    "print(f\"total_img_elements: {total_img_elements}\")\n",
    "print(f\"total_txt_elements: {total_txt_elements}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_prefetch = config.get(\"prefetch_to_device\", 1)\n",
    "train_iter = input_pipeline.start_global(train_ds, devices_flat, n_prefetch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in train_iter:\n",
    "#     # print which process has which batch\n",
    "#     logging.info(f\"process {jax.process_index()} has batch {batch['labels']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### default: replicate sharding strategy, without gradient checkpointing, float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mesh('data': 4), \n",
      "NamedSharding(mesh=Mesh('data': 4), \n",
      "spec=PartitionSpec()), [('.*', 'replicate')]:\n",
      "param memory: 840468480\n",
      "opt memory: 1636944896\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mesh('data': 4), \\nNamedSharding(mesh=Mesh('data': 4), \\nspec=PartitionSpec()), [('.*', 'replicate')]:\")\n",
    "print(f\"param memory: {840481792-13312}\")\n",
    "print(f\"opt memory: {2477426688-840481792}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bfloat16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mesh('data': 4), \n",
      "NamedSharding(mesh=Mesh('data': 4), \n",
      "spec=PartitionSpec()),[('.*', 'replicate')]: \n",
      "model scan = False\n",
      "dtype_mm = bfloat16\n",
      "param memory: 840212992\n",
      "opt memory: 1636300288\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mesh('data': 4), \\nNamedSharding(mesh=Mesh('data': 4), \\nspec=PartitionSpec()),[('.*', 'replicate')]: \")\n",
    "print(f\"model scan = False\")\n",
    "print(f\"img dtype_mm = bfloat16\")\n",
    "print(f\"param memory: {840226304-13312}\")\n",
    "print(f\"opt memory: {2476526592-840226304}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with FSDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mesh('data': 4), \n",
      "NamedSharding(mesh=Mesh('data': 4), \n",
      "spec=PartitionSpec()), [('.*', 'fsdp(axis='data', min_size_to_shard_mb=4)')]: \n",
      "param memory: 416366592\n",
      "opt memory: 777273856\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mesh('data': 4), \\nNamedSharding(mesh=Mesh('data': 4), \\nspec=PartitionSpec()), [('.*', 'fsdp(axis='data', min_size_to_shard_mb=4)')]: \")\n",
    "print(f\"param memory: {416379904-13312}\")\n",
    "print(f\"opt memory: {1193653760-416379904}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mesh('data': 4), \n",
      "NamedSharding(mesh=Mesh('data': 4), \n",
      "spec=PartitionSpec()),[('.*', 'fsdp(axis='data', min_size_to_shard_mb=2)')]: \n",
      "param memory: 273289728\n",
      "opt memory: 454007296\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mesh('data': 4), \\nNamedSharding(mesh=Mesh('data': 4), \\nspec=PartitionSpec()),[('.*', 'fsdp(axis='data', min_size_to_shard_mb=2)')]: \")\n",
    "print(f\"param memory: {273303040-13312}\")\n",
    "print(f\"opt memory: {727310336-273303040}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mesh('data': 4), \n",
      "NamedSharding(mesh=Mesh('data': 4), \n",
      "spec=PartitionSpec()), [('.*', 'fsdp(axis='data', min_size_to_shard_mb=1)')]: \n",
      "param memory: 273289728\n",
      "opt memory: 454007296\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mesh('data': 4), \\nNamedSharding(mesh=Mesh('data': 4), \\nspec=PartitionSpec()), [('.*', 'fsdp(axis='data', min_size_to_shard_mb=1)')]: \")\n",
    "print(f\"param memory: {273303040-13312}\")\n",
    "print(f\"opt memory: {727310336-273303040}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with scan = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mesh('data': 4), \n",
      "NamedSharding(mesh=Mesh('data': 4), \n",
      "spec=PartitionSpec()),[('.*', 'replicate')]: \n",
      "model scan = True\n",
      "param memory: 236565504\n",
      "opt memory: 451496448\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mesh('data': 4), \\nNamedSharding(mesh=Mesh('data': 4), \\nspec=PartitionSpec()),[('.*', 'replicate')]: \")\n",
    "print(f\"model scan = True\")\n",
    "print(f\"param memory: {236578816-13312}\")\n",
    "print(f\"opt memory: {688075264-236578816}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with FSDP & scan=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mesh('data': 4), \n",
      "NamedSharding(mesh=Mesh('data': 4), \n",
      "spec=PartitionSpec()),[('.*', 'fsdp(axis='data', min_size_to_shard_mb=4)')]: \n",
      "model scan = True\n",
      "param memory: 245332480\n",
      "opt memory: 470884352\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mesh('data': 4), \\nNamedSharding(mesh=Mesh('data': 4), \\nspec=PartitionSpec()),[('.*', 'fsdp(axis='data', min_size_to_shard_mb=4)')]: \")\n",
    "print(f\"model scan = True\")\n",
    "print(f\"param memory: {245345792-13312}\")\n",
    "print(f\"opt memory: {716230144-245345792}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mesh('data': 4), \n",
      "NamedSharding(mesh=Mesh('data': 4), \n",
      "spec=PartitionSpec()),[('.*', 'fsdp(axis='data', min_size_to_shard_mb=2)')]: \n",
      "model scan = True\n",
      "param memory: 236565504\n",
      "opt memory: 451496448\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mesh('data': 4), \\nNamedSharding(mesh=Mesh('data': 4), \\nspec=PartitionSpec()),[('.*', 'fsdp(axis='data', min_size_to_shard_mb=2)')]: \")\n",
    "print(f\"model scan = True\")\n",
    "print(f\"param memory: {236578816-13312}\")\n",
    "print(f\"opt memory: {688075264-236578816}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mesh('data': 4), \n",
      "NamedSharding(mesh=Mesh('data': 4), \n",
      "spec=PartitionSpec()),[('.*', 'fsdp(axis='data', min_size_to_shard_mb=1)')]: \n",
      "model scan = True\n",
      "param memory: 236565504\n",
      "opt memory: 451496448\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mesh('data': 4), \\nNamedSharding(mesh=Mesh('data': 4), \\nspec=PartitionSpec()),[('.*', 'fsdp(axis='data', min_size_to_shard_mb=1)')]: \")\n",
    "print(f\"model scan = True\")\n",
    "print(f\"param memory: {236578816-13312}\")\n",
    "print(f\"opt memory: {688075264-236578816}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
